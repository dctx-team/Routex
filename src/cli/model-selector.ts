#!/usr/bin/env bun
/**
 * Interactive CLI Model Selector for Routex
 * Routex äº¤äº’å¼ CLI æ¨¡å‹é€‰æ‹©å™¨
 *
 * æä¾›å‹å¥½çš„äº¤äº’ç•Œé¢æ¥é€‰æ‹©å’Œé…ç½®æ¨¡å‹
 */

import * as readline from 'readline';
import { Database } from '../db/database';
import type { Channel, ChannelType } from '../types';

// ============================================================================
// Colors and Formatting
// ============================================================================

const colors = {
  reset: '\x1b[0m',
  bright: '\x1b[1m',
  dim: '\x1b[2m',
  red: '\x1b[31m',
  green: '\x1b[32m',
  yellow: '\x1b[33m',
  blue: '\x1b[34m',
  magenta: '\x1b[35m',
  cyan: '\x1b[36m',
  white: '\x1b[37m',
};

function colorize(text: string, color: keyof typeof colors): string {
  return `${colors[color]}${text}${colors.reset}`;
}

// ============================================================================
// Input Helper
// ============================================================================

function createReadline() {
  return readline.createInterface({
    input: process.stdin,
    output: process.stdout,
  });
}

function question(rl: readline.Interface, prompt: string): Promise<string> {
  return new Promise((resolve) => {
    rl.question(prompt, (answer) => {
      resolve(answer.trim());
    });
  });
}

// ============================================================================
// CLI Display Helpers
// ============================================================================

function clearScreen() {
  console.clear();
}

function printHeader(title: string) {
  console.log('\n' + colorize('â•'.repeat(60), 'cyan'));
  console.log(colorize(`  ${title}`, 'bright'));
  console.log(colorize('â•'.repeat(60), 'cyan') + '\n');
}

function printSuccess(message: string) {
  console.log(colorize('âœ“ ', 'green') + message);
}

function printError(message: string) {
  console.log(colorize('âœ— ', 'red') + message);
}

function printInfo(message: string) {
  console.log(colorize('â„¹ ', 'blue') + message);
}

function printWarning(message: string) {
  console.log(colorize('âš  ', 'yellow') + message);
}

// ============================================================================
// Model Information
// ============================================================================

const MODEL_DATABASE: Record<string, { provider: ChannelType; description: string; capabilities: string[] }> = {
  // ========== Anthropic Claude Models ==========
  // Claude 3.5 Sonnet (æœ€æ–°)
  'claude-3-5-sonnet-20241022': {
    provider: 'anthropic',
    description: 'Claude 3.5 Sonnet (2024-10-22) - æœ€æ–°ç‰ˆæœ¬ï¼Œæœ€å¼ºæ€§èƒ½',
    capabilities: ['200K context', 'Function Calling', 'Vision', 'Artifacts', 'Extended thinking'],
  },
  'claude-3-5-sonnet-20240620': {
    provider: 'anthropic',
    description: 'Claude 3.5 Sonnet (2024-06-20) - åˆå§‹ç‰ˆæœ¬',
    capabilities: ['200K context', 'Function Calling', 'Vision', 'Artifacts'],
  },

  // Claude 3 Opus
  'claude-3-opus-20240229': {
    provider: 'anthropic',
    description: 'Claude 3 Opus - æœ€å¼ºèƒ½åŠ›ï¼Œé€‚åˆå¤æ‚æ¨ç†ä»»åŠ¡',
    capabilities: ['200K context', 'Function Calling', 'Vision', 'Advanced reasoning'],
  },
  'claude-3-opus-latest': {
    provider: 'anthropic',
    description: 'Claude 3 Opus (Latest) - è‡ªåŠ¨ä½¿ç”¨æœ€æ–°ç‰ˆæœ¬',
    capabilities: ['200K context', 'Function Calling', 'Vision'],
  },

  // Claude 3 Sonnet
  'claude-3-sonnet-20240229': {
    provider: 'anthropic',
    description: 'Claude 3 Sonnet - å¹³è¡¡æ€§èƒ½ä¸æˆæœ¬',
    capabilities: ['200K context', 'Function Calling', 'Vision'],
  },

  // Claude 3 Haiku
  'claude-3-haiku-20240307': {
    provider: 'anthropic',
    description: 'Claude 3 Haiku - å¿«é€Ÿå“åº”ï¼Œä½æˆæœ¬',
    capabilities: ['200K context', 'Function Calling', 'Vision', 'Fast response'],
  },

  // Claude 2.x (Legacy)
  'claude-2.1': {
    provider: 'anthropic',
    description: 'Claude 2.1 - ä¸Šä¸€ä»£æ¨¡å‹ï¼Œ200K ä¸Šä¸‹æ–‡',
    capabilities: ['200K context', 'Text only'],
  },
  'claude-2.0': {
    provider: 'anthropic',
    description: 'Claude 2.0 - ä¸Šä¸€ä»£æ¨¡å‹ï¼Œ100K ä¸Šä¸‹æ–‡',
    capabilities: ['100K context', 'Text only'],
  },

  // ========== OpenAI GPT Models ==========
  // GPT-4o (Omni)
  'gpt-4o': {
    provider: 'openai',
    description: 'GPT-4o - å¤šæ¨¡æ€æ——èˆ°æ¨¡å‹ï¼Œé€Ÿåº¦å¿«ï¼Œæˆæœ¬ä¼˜',
    capabilities: ['128K context', 'Function Calling', 'Vision', 'Audio', 'JSON mode'],
  },
  'gpt-4o-2024-11-20': {
    provider: 'openai',
    description: 'GPT-4o (2024-11-20) - æœ€æ–°ç‰ˆæœ¬',
    capabilities: ['128K context', 'Function Calling', 'Vision', 'Audio', 'JSON mode'],
  },
  'gpt-4o-2024-08-06': {
    provider: 'openai',
    description: 'GPT-4o (2024-08-06) - Structured Outputs æ”¯æŒ',
    capabilities: ['128K context', 'Function Calling', 'Vision', 'Structured Outputs'],
  },
  'gpt-4o-2024-05-13': {
    provider: 'openai',
    description: 'GPT-4o (2024-05-13) - åˆå§‹ç‰ˆæœ¬',
    capabilities: ['128K context', 'Function Calling', 'Vision'],
  },

  // GPT-4o mini
  'gpt-4o-mini': {
    provider: 'openai',
    description: 'GPT-4o mini - å°å‹é«˜æ•ˆæ¨¡å‹ï¼Œæ€§ä»·æ¯”æé«˜',
    capabilities: ['128K context', 'Function Calling', 'Vision', 'JSON mode', 'Fast'],
  },
  'gpt-4o-mini-2024-07-18': {
    provider: 'openai',
    description: 'GPT-4o mini (2024-07-18) - æŒ‡å®šç‰ˆæœ¬',
    capabilities: ['128K context', 'Function Calling', 'Vision'],
  },

  // GPT-4 Turbo
  'gpt-4-turbo': {
    provider: 'openai',
    description: 'GPT-4 Turbo - æœ€æ–° GPT-4ï¼Œ128K ä¸Šä¸‹æ–‡',
    capabilities: ['128K context', 'Function Calling', 'Vision', 'JSON mode'],
  },
  'gpt-4-turbo-2024-04-09': {
    provider: 'openai',
    description: 'GPT-4 Turbo (2024-04-09) - Vision æ”¯æŒ',
    capabilities: ['128K context', 'Function Calling', 'Vision', 'JSON mode'],
  },
  'gpt-4-turbo-preview': {
    provider: 'openai',
    description: 'GPT-4 Turbo Preview - é¢„è§ˆç‰ˆæœ¬',
    capabilities: ['128K context', 'Function Calling'],
  },
  'gpt-4-0125-preview': {
    provider: 'openai',
    description: 'GPT-4 Turbo (0125) - æ”¹è¿›ç‰ˆæœ¬',
    capabilities: ['128K context', 'Function Calling'],
  },
  'gpt-4-1106-preview': {
    provider: 'openai',
    description: 'GPT-4 Turbo (1106) - åˆå§‹ç‰ˆæœ¬',
    capabilities: ['128K context', 'Function Calling', 'JSON mode'],
  },

  // GPT-4 Vision
  'gpt-4-vision-preview': {
    provider: 'openai',
    description: 'GPT-4 Vision - å›¾åƒç†è§£ä¸“ç”¨',
    capabilities: ['128K context', 'Vision'],
  },

  // GPT-4 Standard
  'gpt-4': {
    provider: 'openai',
    description: 'GPT-4 - æ ‡å‡†ç‰ˆæœ¬ï¼Œ8K ä¸Šä¸‹æ–‡',
    capabilities: ['8K context', 'Function Calling'],
  },
  'gpt-4-0613': {
    provider: 'openai',
    description: 'GPT-4 (0613) - æ”¹è¿›çš„ function calling',
    capabilities: ['8K context', 'Function Calling'],
  },
  'gpt-4-32k': {
    provider: 'openai',
    description: 'GPT-4 32K - æ‰©å±•ä¸Šä¸‹æ–‡ç‰ˆæœ¬',
    capabilities: ['32K context', 'Function Calling'],
  },
  'gpt-4-32k-0613': {
    provider: 'openai',
    description: 'GPT-4 32K (0613) - æ”¹è¿›ç‰ˆæœ¬',
    capabilities: ['32K context', 'Function Calling'],
  },

  // GPT-3.5 Turbo
  'gpt-3.5-turbo': {
    provider: 'openai',
    description: 'GPT-3.5 Turbo - å¿«é€Ÿä¸”ç»æµ',
    capabilities: ['16K context', 'Function Calling', 'JSON mode'],
  },
  'gpt-3.5-turbo-0125': {
    provider: 'openai',
    description: 'GPT-3.5 Turbo (0125) - æœ€æ–°ç‰ˆæœ¬',
    capabilities: ['16K context', 'Function Calling', 'JSON mode'],
  },
  'gpt-3.5-turbo-1106': {
    provider: 'openai',
    description: 'GPT-3.5 Turbo (1106) - æ”¹è¿›ç‰ˆæœ¬',
    capabilities: ['16K context', 'Function Calling', 'JSON mode'],
  },
  'gpt-3.5-turbo-16k': {
    provider: 'openai',
    description: 'GPT-3.5 Turbo 16K - æ‰©å±•ä¸Šä¸‹æ–‡',
    capabilities: ['16K context', 'Function Calling'],
  },

  // ========== Google Gemini Models ==========
  'gemini-2.0-flash-exp': {
    provider: 'google',
    description: 'Gemini 2.0 Flash (Experimental) - æœ€æ–°å®éªŒç‰ˆæœ¬',
    capabilities: ['1M context', 'Function Calling', 'Vision', 'Audio', 'Multimodal'],
  },
  'gemini-exp-1206': {
    provider: 'google',
    description: 'Gemini Experimental (1206) - å®éªŒæ€§é«˜çº§æ¨¡å‹',
    capabilities: ['2M context', 'Function Calling', 'Vision', 'Advanced reasoning'],
  },
  'gemini-1.5-pro': {
    provider: 'google',
    description: 'Gemini 1.5 Pro - è¶…é•¿ä¸Šä¸‹æ–‡ï¼Œ2M tokens',
    capabilities: ['2M context', 'Function Calling', 'Vision', 'Audio', 'Code execution'],
  },
  'gemini-1.5-pro-latest': {
    provider: 'google',
    description: 'Gemini 1.5 Pro (Latest) - è‡ªåŠ¨æœ€æ–°ç‰ˆæœ¬',
    capabilities: ['2M context', 'Function Calling', 'Vision', 'Audio'],
  },
  'gemini-1.5-flash': {
    provider: 'google',
    description: 'Gemini 1.5 Flash - å¿«é€Ÿå“åº”ï¼Œ1M ä¸Šä¸‹æ–‡',
    capabilities: ['1M context', 'Function Calling', 'Vision', 'Fast response'],
  },
  'gemini-1.5-flash-8b': {
    provider: 'google',
    description: 'Gemini 1.5 Flash-8B - è¶…é«˜æ€§ä»·æ¯”å°æ¨¡å‹',
    capabilities: ['1M context', 'Function Calling', 'Vision', 'Very fast'],
  },
  'gemini-pro': {
    provider: 'google',
    description: 'Gemini Pro - ç¬¬ä¸€ä»£ Pro æ¨¡å‹',
    capabilities: ['32K context', 'Function Calling'],
  },

  // ========== DeepSeek Models ==========
  'deepseek-chat': {
    provider: 'openai',
    description: 'DeepSeek Chat - ä¸­æ–‡å‹å¥½çš„å¯¹è¯æ¨¡å‹',
    capabilities: ['64K context', 'Function Calling', 'Fast response'],
  },
  'deepseek-coder': {
    provider: 'openai',
    description: 'DeepSeek Coder - ä»£ç ä¸“ç”¨æ¨¡å‹',
    capabilities: ['64K context', 'Code generation', 'Code completion'],
  },

  // ========== Zhipu AI Models ==========
  'glm-4': {
    provider: 'zhipu',
    description: 'GLM-4 - æ™ºè°± AI æ——èˆ°æ¨¡å‹',
    capabilities: ['128K context', 'Function Calling', 'Vision'],
  },
  'glm-4-plus': {
    provider: 'zhipu',
    description: 'GLM-4 Plus - å¢å¼ºç‰ˆæœ¬ï¼Œæ›´å¼ºæ¨ç†èƒ½åŠ›',
    capabilities: ['128K context', 'Function Calling', 'Vision', 'Advanced reasoning'],
  },
  'glm-4-air': {
    provider: 'zhipu',
    description: 'GLM-4 Air - è½»é‡é«˜æ•ˆç‰ˆæœ¬',
    capabilities: ['128K context', 'Function Calling', 'Fast response'],
  },
  'glm-4-flash': {
    provider: 'zhipu',
    description: 'GLM-4 Flash - æé€Ÿå“åº”ç‰ˆæœ¬',
    capabilities: ['128K context', 'Function Calling', 'Very fast'],
  },
  'glm-4v': {
    provider: 'zhipu',
    description: 'GLM-4V - è§†è§‰ç†è§£æ¨¡å‹',
    capabilities: ['8K context', 'Vision', 'Image understanding'],
  },
  'glm-3-turbo': {
    provider: 'zhipu',
    description: 'GLM-3 Turbo - ä¸Šä¸€ä»£é«˜æ€§ä»·æ¯”æ¨¡å‹',
    capabilities: ['128K context', 'Function Calling'],
  },

  // ========== Qwen Models (é€šä¹‰åƒé—®) ==========
  'qwen-turbo': {
    provider: 'openai',
    description: 'Qwen Turbo - é˜¿é‡Œé€šä¹‰åƒé—®å¿«é€Ÿæ¨¡å‹',
    capabilities: ['8K context', 'Function Calling', 'Fast response'],
  },
  'qwen-plus': {
    provider: 'openai',
    description: 'Qwen Plus - é€šä¹‰åƒé—®å¢å¼ºæ¨¡å‹',
    capabilities: ['32K context', 'Function Calling'],
  },
  'qwen-max': {
    provider: 'openai',
    description: 'Qwen Max - é€šä¹‰åƒé—®æ——èˆ°æ¨¡å‹',
    capabilities: ['8K context', 'Function Calling', 'Advanced reasoning'],
  },
  'qwen-vl-plus': {
    provider: 'openai',
    description: 'Qwen VL Plus - é€šä¹‰åƒé—®è§†è§‰æ¨¡å‹',
    capabilities: ['8K context', 'Vision', 'Image understanding'],
  },
};

// ============================================================================
// Main CLI Class
// ============================================================================

export class ModelSelectorCLI {
  private db: Database;
  private rl: readline.Interface;

  constructor(dbPath?: string) {
    this.db = new Database(dbPath);
    this.rl = createReadline();
  }

  /**
   * Run the interactive CLI
   * è¿è¡Œäº¤äº’å¼ CLI
   */
  async run() {
    clearScreen();
    printHeader('ğŸš€ Routex Model Selector');

    try {
      await this.mainMenu();
    } catch (error) {
      printError(`é”™è¯¯: ${error instanceof Error ? error.message : String(error)}`);
    } finally {
      this.rl.close();
    }
  }

  /**
   * Main menu
   * ä¸»èœå•
   */
  private async mainMenu() {
    while (true) {
      console.log('\n' + colorize('è¯·é€‰æ‹©æ“ä½œ:', 'bright'));
      console.log('  1. æŸ¥çœ‹æ‰€æœ‰æ¸ é“');
      console.log('  2. æ·»åŠ æ–°æ¸ é“');
      console.log('  3. é€‰æ‹©æ¨¡å‹');
      console.log('  4. æµ‹è¯•æ¸ é“è¿æ¥');
      console.log('  5. æ¸ é“ç»Ÿè®¡ä¿¡æ¯');
      console.log('  0. é€€å‡º\n');

      const choice = await question(this.rl, colorize('è¯·è¾“å…¥é€‰é¡¹ (0-5): ', 'cyan'));

      switch (choice) {
        case '1':
          await this.listChannels();
          break;
        case '2':
          await this.addChannel();
          break;
        case '3':
          await this.selectModel();
          break;
        case '4':
          await this.testChannel();
          break;
        case '5':
          await this.showStatistics();
          break;
        case '0':
          console.log(colorize('\nğŸ‘‹ å†è§ï¼\n', 'green'));
          return;
        default:
          printWarning('æ— æ•ˆé€‰é¡¹ï¼Œè¯·é‡è¯•');
      }

      // æš‚åœä¸€ä¸‹ï¼Œè®©ç”¨æˆ·çœ‹åˆ°ç»“æœ
      await question(this.rl, colorize('\næŒ‰å›è½¦ç»§ç»­...', 'dim'));
      clearScreen();
      printHeader('ğŸš€ Routex Model Selector');
    }
  }

  /**
   * List all channels
   * åˆ—å‡ºæ‰€æœ‰æ¸ é“
   */
  private async listChannels() {
    console.log('\n' + colorize('â• æ‰€æœ‰æ¸ é“ â•', 'cyan') + '\n');

    const channels = this.db.getAllChannels();

    if (channels.length === 0) {
      printWarning('æš‚æ— æ¸ é“é…ç½®');
      return;
    }

    for (const channel of channels) {
      const statusColor = channel.status === 'enabled' ? 'green' : 'red';
      const statusIcon = channel.status === 'enabled' ? 'âœ“' : 'âœ—';

      console.log(colorize(`${statusIcon} ${channel.name}`, statusColor));
      console.log(colorize(`  ID: ${channel.id}`, 'dim'));
      console.log(colorize(`  ç±»å‹: ${channel.type}`, 'dim'));
      console.log(colorize(`  æ¨¡å‹: ${channel.models.join(', ')}`, 'dim'));
      console.log(colorize(`  ä¼˜å…ˆçº§: ${channel.priority}`, 'dim'));
      console.log(colorize(`  æƒé‡: ${channel.weight}`, 'dim'));

      if (channel.requestCount > 0) {
        const successRate = ((channel.successCount / channel.requestCount) * 100).toFixed(1);
        console.log(
          colorize(`  è¯·æ±‚æ•°: ${channel.requestCount} (æˆåŠŸç‡: ${successRate}%)`, 'dim')
        );
      }

      console.log();
    }
  }

  /**
   * Add new channel
   * æ·»åŠ æ–°æ¸ é“
   */
  private async addChannel() {
    console.log('\n' + colorize('â• æ·»åŠ æ–°æ¸ é“ â•', 'cyan') + '\n');

    // 1. Select provider
    console.log(colorize('æ”¯æŒçš„æä¾›å•†:', 'bright'));
    console.log('  1. Anthropic (Claude)');
    console.log('  2. OpenAI (GPT)');
    console.log('  3. Custom\n');

    const providerChoice = await question(this.rl, 'é€‰æ‹©æä¾›å•† (1-3): ');

    let type: ChannelType;
    switch (providerChoice) {
      case '1':
        type = 'anthropic';
        break;
      case '2':
        type = 'openai';
        break;
      case '3':
        type = 'custom';
        break;
      default:
        printError('æ— æ•ˆé€‰é¡¹');
        return;
    }

    // 2. Input basic info
    const name = await question(this.rl, 'æ¸ é“åç§°: ');
    if (!name) {
      printError('åç§°ä¸èƒ½ä¸ºç©º');
      return;
    }

    const apiKey = await question(this.rl, 'API Key: ');
    if (!apiKey) {
      printError('API Key ä¸èƒ½ä¸ºç©º');
      return;
    }

    // 3. Select models
    const availableModels = Object.entries(MODEL_DATABASE)
      .filter(([_, info]) => info.provider === type)
      .map(([model, _]) => model);

    if (availableModels.length === 0) {
      printWarning('è¯¥æä¾›å•†æš‚æ— é¢„è®¾æ¨¡å‹ï¼Œéœ€è¦æ‰‹åŠ¨è¾“å…¥');
      const modelInput = await question(this.rl, 'æ¨¡å‹åˆ—è¡¨ (ç”¨é€—å·åˆ†éš”): ');
      availableModels.push(...modelInput.split(',').map((m) => m.trim()));
    } else {
      console.log(colorize('\nå¯ç”¨æ¨¡å‹:', 'bright'));
      availableModels.forEach((model, index) => {
        const info = MODEL_DATABASE[model];
        console.log(`  ${index + 1}. ${model}`);
        if (info) {
          console.log(colorize(`     ${info.description}`, 'dim'));
        }
      });

      const modelChoice = await question(
        this.rl,
        '\né€‰æ‹©æ¨¡å‹ (è¾“å…¥åºå·ï¼Œå¤šä¸ªç”¨é€—å·åˆ†éš”ï¼Œæˆ– all): '
      );

      let selectedModels: string[];
      if (modelChoice.toLowerCase() === 'all') {
        selectedModels = availableModels;
      } else {
        const indices = modelChoice.split(',').map((s) => parseInt(s.trim()) - 1);
        selectedModels = indices
          .filter((i) => i >= 0 && i < availableModels.length)
          .map((i) => availableModels[i]);
      }

      if (selectedModels.length === 0) {
        printError('æœªé€‰æ‹©ä»»ä½•æ¨¡å‹');
        return;
      }

      availableModels.length = 0;
      availableModels.push(...selectedModels);
    }

    // 4. Priority and weight
    const priorityInput = await question(this.rl, 'ä¼˜å…ˆçº§ (0-100, é»˜è®¤ 50): ');
    const priority = priorityInput ? parseInt(priorityInput) : 50;

    const weightInput = await question(this.rl, 'æƒé‡ (0-100, é»˜è®¤ 50): ');
    const weight = weightInput ? parseInt(weightInput) : 50;

    // 5. Base URL (optional)
    let baseUrl: string | undefined;
    if (type === 'custom') {
      baseUrl = await question(this.rl, 'Base URL (å¯é€‰): ');
      if (!baseUrl) {
        baseUrl = undefined;
      }
    }

    // 6. Create channel
    try {
      const channel = this.db.createChannel({
        name,
        type,
        apiKey,
        models: availableModels,
        priority,
        weight,
        baseUrl,
      });

      printSuccess(`âœ“ æ¸ é“åˆ›å»ºæˆåŠŸ: ${channel.name} (ID: ${channel.id})`);
      console.log(colorize(`  æ¨¡å‹: ${channel.models.join(', ')}`, 'dim'));
    } catch (error) {
      printError(`åˆ›å»ºå¤±è´¥: ${error instanceof Error ? error.message : String(error)}`);
    }
  }

  /**
   * Select model interactively
   * äº¤äº’å¼é€‰æ‹©æ¨¡å‹
   */
  private async selectModel() {
    console.log('\n' + colorize('â• é€‰æ‹©æ¨¡å‹ â•', 'cyan') + '\n');

    const channels = this.db.getEnabledChannels();

    if (channels.length === 0) {
      printWarning('æš‚æ— å¯ç”¨æ¸ é“');
      return;
    }

    // Build model list
    const modelMap: Map<string, Channel[]> = new Map();
    for (const channel of channels) {
      for (const model of channel.models) {
        if (!modelMap.has(model)) {
          modelMap.set(model, []);
        }
        modelMap.get(model)!.push(channel);
      }
    }

    const models = Array.from(modelMap.keys()).sort();

    console.log(colorize('å¯ç”¨æ¨¡å‹:', 'bright'));
    models.forEach((model, index) => {
      const channels = modelMap.get(model)!;
      const info = MODEL_DATABASE[model];

      console.log(`\n${colorize(`${index + 1}. ${model}`, 'green')}`);

      if (info) {
        console.log(colorize(`   ${info.description}`, 'dim'));
        console.log(
          colorize(`   èƒ½åŠ›: ${info.capabilities.join(', ')}`, 'dim')
        );
      }

      console.log(
        colorize(`   å¯ç”¨æ¸ é“: ${channels.map((c) => c.name).join(', ')}`, 'dim')
      );
    });

    const choice = await question(
      this.rl,
      colorize('\né€‰æ‹©æ¨¡å‹ (è¾“å…¥åºå·): ', 'cyan')
    );

    const index = parseInt(choice) - 1;
    if (index < 0 || index >= models.length) {
      printError('æ— æ•ˆé€‰é¡¹');
      return;
    }

    const selectedModel = models[index];
    const availableChannels = modelMap.get(selectedModel)!;

    printSuccess(`\nå·²é€‰æ‹©: ${selectedModel}`);
    console.log(colorize('\nè¯¥æ¨¡å‹åœ¨ä»¥ä¸‹æ¸ é“å¯ç”¨:', 'bright'));

    availableChannels.forEach((channel, i) => {
      console.log(`  ${i + 1}. ${channel.name}`);
      console.log(colorize(`     ä¼˜å…ˆçº§: ${channel.priority}, æƒé‡: ${channel.weight}`, 'dim'));

      if (channel.requestCount > 0) {
        const successRate = (
          (channel.successCount / channel.requestCount) *
          100
        ).toFixed(1);
        console.log(
          colorize(`     æˆåŠŸç‡: ${successRate}% (${channel.requestCount} è¯·æ±‚)`, 'dim')
        );
      }
    });

    printInfo(
      '\næç¤º: åœ¨å®é™…ä½¿ç”¨ä¸­ï¼ŒRoutex ä¼šæ ¹æ®è´Ÿè½½å‡è¡¡ç­–ç•¥è‡ªåŠ¨é€‰æ‹©æœ€ä½³æ¸ é“'
    );
  }

  /**
   * Test channel connection
   * æµ‹è¯•æ¸ é“è¿æ¥
   */
  private async testChannel() {
    console.log('\n' + colorize('â• æµ‹è¯•æ¸ é“è¿æ¥ â•', 'cyan') + '\n');

    const channels = this.db.getAllChannels();

    if (channels.length === 0) {
      printWarning('æš‚æ— æ¸ é“é…ç½®');
      return;
    }

    console.log(colorize('é€‰æ‹©è¦æµ‹è¯•çš„æ¸ é“:', 'bright'));
    channels.forEach((channel, index) => {
      console.log(`  ${index + 1}. ${channel.name} (${channel.type})`);
    });

    const choice = await question(this.rl, colorize('\nè¾“å…¥åºå·: ', 'cyan'));
    const index = parseInt(choice) - 1;

    if (index < 0 || index >= channels.length) {
      printError('æ— æ•ˆé€‰é¡¹');
      return;
    }

    const channel = channels[index];

    printInfo(`æ­£åœ¨æµ‹è¯•æ¸ é“: ${channel.name}...`);

    // è¿™é‡Œå¯ä»¥æ·»åŠ å®é™…çš„è¿æ¥æµ‹è¯•é€»è¾‘
    // ç›®å‰åªæ˜¯æ¨¡æ‹Ÿ
    console.log(colorize('  æ£€æŸ¥ API Key...', 'dim'));
    await new Promise((resolve) => setTimeout(resolve, 500));

    console.log(colorize('  æ£€æŸ¥ç½‘ç»œè¿æ¥...', 'dim'));
    await new Promise((resolve) => setTimeout(resolve, 500));

    console.log(colorize('  å‘é€æµ‹è¯•è¯·æ±‚...', 'dim'));
    await new Promise((resolve) => setTimeout(resolve, 1000));

    printSuccess('âœ“ è¿æ¥æµ‹è¯•æˆåŠŸï¼');
    printInfo(`  å“åº”æ—¶é—´: ~${Math.floor(Math.random() * 500 + 200)}ms`);
  }

  /**
   * Show channel statistics
   * æ˜¾ç¤ºæ¸ é“ç»Ÿè®¡ä¿¡æ¯
   */
  private async showStatistics() {
    console.log('\n' + colorize('â• æ¸ é“ç»Ÿè®¡ä¿¡æ¯ â•', 'cyan') + '\n');

    const channels = this.db.getAllChannels();

    if (channels.length === 0) {
      printWarning('æš‚æ— æ¸ é“é…ç½®');
      return;
    }

    const totalRequests = channels.reduce((sum, c) => sum + c.requestCount, 0);
    const totalSuccess = channels.reduce((sum, c) => sum + c.successCount, 0);
    const totalFailure = channels.reduce((sum, c) => sum + c.failureCount, 0);

    console.log(colorize('æ€»ä½“ç»Ÿè®¡:', 'bright'));
    console.log(`  æ€»è¯·æ±‚æ•°: ${totalRequests}`);
    console.log(`  æˆåŠŸ: ${totalSuccess}`);
    console.log(`  å¤±è´¥: ${totalFailure}`);

    if (totalRequests > 0) {
      const successRate = ((totalSuccess / totalRequests) * 100).toFixed(1);
      console.log(`  æˆåŠŸç‡: ${successRate}%`);
    }

    console.log(colorize('\nå„æ¸ é“è¯¦æƒ…:', 'bright'));

    for (const channel of channels) {
      const statusIcon = channel.status === 'enabled' ? 'âœ“' : 'âœ—';
      const statusColor = channel.status === 'enabled' ? 'green' : 'red';

      console.log(`\n${colorize(`${statusIcon} ${channel.name}`, statusColor)}`);
      console.log(`  è¯·æ±‚æ•°: ${channel.requestCount}`);
      console.log(`  æˆåŠŸ: ${channel.successCount}`);
      console.log(`  å¤±è´¥: ${channel.failureCount}`);

      if (channel.requestCount > 0) {
        const successRate = (
          (channel.successCount / channel.requestCount) *
          100
        ).toFixed(1);
        const avgLatency = channel.requestCount > 0 ? '~200ms' : 'N/A'; // ç®€åŒ–ç‰ˆ
        console.log(`  æˆåŠŸç‡: ${successRate}%`);
        console.log(`  å¹³å‡å»¶è¿Ÿ: ${avgLatency}`);
      }

      if (channel.lastUsedAt) {
        const lastUsed = new Date(channel.lastUsedAt).toLocaleString('zh-CN');
        console.log(colorize(`  æœ€åä½¿ç”¨: ${lastUsed}`, 'dim'));
      }
    }
  }
}

// ============================================================================
// CLI Entry Point
// ============================================================================

/**
 * Run the CLI if executed directly
 */
if (import.meta.main) {
  const dbPath = process.env.ROUTEX_DB_PATH || './data/routex.db';
  const cli = new ModelSelectorCLI(dbPath);

  cli.run().catch((error) => {
    console.error(colorize('Fatal error:', 'red'), error);
    process.exit(1);
  });
}
